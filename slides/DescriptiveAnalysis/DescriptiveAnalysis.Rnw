\documentclass{beamer}

\def\currentCourse{An introduction to graph analysis and modeling}
\def\currentInstitute{Julien Chiquet}
\def\currentLogo{../common_figs/logo_imperial}
\def\currentDate{March, 2020}
\def\currentChapter{Descriptive Analysis of Network Data}

<<preamble, child='../common_preamble.Rnw'>>=
@

<<load_packages, cache = FALSE, echo=FALSE>>=
library(igraph)
library(sand)
@

\usetikzlibrary{calc,shapes,backgrounds,arrows,automata,shadows,positioning}

\begin{document}

\dotitlepage

% \begin{frame} 
%   \frametitle{References}
% 
%     \begin{thebibliography}{99}
%       \setbeamertemplate{bibliography item}[book]
% 
%     \bibitem[EK2]{EK2} Statistical Analysis of Network Data: Methods and Models, 
%     \newblock \textcolor{black}{Eric Kolazcyk}
%     \newblock \alert{Chapiter 4, Sections 2 and 3}
% 
%     \bibitem[EK1]{EK1} Statistical Analysis of Network Data with \texttt{R}, 
%     \newblock \textcolor{black}{Eric Kolazcyk, G\'abor Cs\'ardi}
%     \newblock \alert{Chapiter 4, Sections 2 and 3}
% 
%       \setbeamertemplate{bibliography item}[article]
% 
%     \bibitem[CM1]{CM1} Analyse statistique de graphes, 
%     \newblock \textcolor{black}{Catherine Matias}
%     \newblock \alert{Chapitre 2}
% 
%     \end{thebibliography}
% 
% \end{frame}

%% ==========================================================================

\begin{frame}
  \frametitle{Statistical analysis of Networks}
  \framesubtitle{Different questions}

  \begin{alertblock}{Understanding the network topology}
    \vspace{-.25cm}
    \begin{itemize}
    \item Data = observed network
    \item Questions: central nodes? cluster structure? small-world property?
    \end{itemize}
  \end{alertblock}
  
  \vfill

  \begin{block}{Inferring/Reconstructing the network}
    \vspace{-.25cm}
    \begin{itemize}
    \item Data = repeated signal observed at each node
    \item Questions: which nodes are connected?
    \end{itemize}
  \end{block}

  \vfill

  \begin{block}{\alert{Each to be combined with}}
    covariates, time, heterogeneous data set, missing data, ...  
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Reconstruction and analysis of biological networks} 
  \framesubtitle{E. coli regulatory network}  

  \begin{columns}
    \begin{column}{.4\textwidth}
      \begin{small}
        \begin{block}{Target network}
          Relations between genes and their products
          \begin{itemize}
          \item highly structured
          \item always incomplete
          \end{itemize}
        \end{block}
      \end{small}
      \begin{small}
        \begin{block}{Data and method}
          \begin{itemize}
          \item transcriptomic data
          \item \alert{Inference}: sparse Gaussian graphical model
          \item \alert{Analysis}: Stochastic Block Model
          \end{itemize}
        \end{block}
      \end{small}
    \end{column}
    \begin{column}{.55\textwidth}
      \includegraphics[width=\textwidth]{figures/net_reg_ecoli}
    \end{column}
  \end{columns}
\end{frame}

%% ==========================================================================

\begin{frame}
  \frametitle{Outline}
  \tableofcontents[hideallsubsections]
\end{frame}

%% ==========================================================================
\section{Basic notions on graphs and networks}
%% ==========================================================================

\begin{frame}
  \frametitle{Graphs, Networks: some definitions}

  \begin{definition}[Network versus Graph]
    \vspace{-.25cm}
    \begin{itemize}
      \item  A \alert{Network} is a collection of interacting entities
      \item  A \alert{Graph} is the mathematical representation of a network
    \end{itemize}
  \end{definition}

  \vfill

  \begin{definition}[Graph]
    A graph $\clG=(\clV,\clE)$ is a mathematical structure consisting of
    \begin{itemize}
      \item a set $\clV=\set{1,\dots,n}$ of \alert{vertices} or \alert{nodes} 
      \item a set $\clE=\set{e_1,\dots,e_p:e_k=(i_k,j_k)\in (\clV\times\clV)}$ of \alert{edges} or \alert{links} 
      \item The number of vertices $N_v=|\clV|$ is called the \alert{order}
      \item The number of edges $N_e=|\clE|$ is called the \alert{size}
    \end{itemize}
  \end{definition}

  \vfill

  \begin{definition}[Vocabulary]
  subgraph,  induced subgraph, (un)directed graph, 
  weighted graph, bipartite graph, tree, DAG,path, cycle, connected components, etc.
  \end{definition}

\end{frame}

\begin{frame}[fragile]
\frametitle{Examples}
\framesubtitle{Undirected, directed (digraph), complete, bipartite}

<<basic_graphs, echo=FALSE>>=
par(mfrow=c(2,2))
plot(graph_from_literal(a---b, b---c))
plot(graph_from_literal(a+--b, b+--c))
plot(graph_from_literal(a:b:c---c:d:e))
plot(graph_from_literal(a---c, b---d), vertex.color=c("red", "red", "blue", "blue"))
@

\end{frame}

\begin{frame}
  \frametitle{Neighborhood, Degree}

  \begin{definition}[Neighborhood]
    The neighbors of a vertex are the nodes directly connected to this vertex:
    \[
      \clN(i) = \set{j\in\clV : (i,j) \in \clE}.
    \]
  \end{definition}
  
  \begin{definition}[Degree]
    The degree $d_i$ of a node $i$ is given by its number of neighbors, i.e. $|\clN(i)|$.
  \end{definition}

  \begin{block}{Remark}
    In digraphs, vertex degree is replaced by \alert{in-degree} and \alert{out-degree}.
  \end{block}

  \begin{proposition}
    In a graph $\clG = (\clV,\clE)$ the sum of the degree is given by $2|\clE|$. Hence \alert{this is always an even quantity}.
  \end{proposition}
  
  
\end{frame}

\begin{frame}
  \frametitle{Adjacency matrix and list of edges}

  \begin{definition}[Adjacency matrix]
    The connectivity of  $\clG = (\clV,\clE)$ is captured by the $|\clV|\times |\clV|$ matrix $\bA$:
    \[
      (\bA)_{ij} = \begin{cases}
      1  & \text{ if } i \sim j,\\
      0  & \text{otherwise}.
      \end{cases}
    \]
  \end{definition}

  \begin{proposition}
    The degrees of $\clG$ are then simply obtained as the row-wise and/or column-wise sums of $\bA$.
  \end{proposition}

  \begin{block}{Remark}
    If the list of vertices is known, the only information which needs to be stored is the list of edges. In terms of storage, this is equivalent to a sparse matrix representation.
  \end{block}
  
\end{frame}

\begin{frame}
  \frametitle{Layout and Vizualization}
  
  \begin{itemize}
    \item Vizualization of large networks is a field of research in its own
    \item Be carefull with graphical interpretation of (large) networks
  \end{itemize}

<<vizu_1, echo=TRUE>>=
library(igraph)

library(sand)

GLattice <- graph.lattice(c(5,5,5))

GBlog    <- aidsblog
@
  
\end{frame}

\begin{frame}
  \frametitle{Layout and Vizualization}
  \framesubtitle{Example with circle plot}

<<vizu_2, echo=FALSE>>=
igraph.options(vertex.size=3, vertex.label=NA, edge.arrow.size=.5)
@

<<vizu_3, echo=TRUE>>=
par(mfrow=c(1,2))

plot(GLattice, layout=layout.circle); title("5x5x5 lattice")

plot(GBlog   , layout=layout.circle); title("blog network")
@
  
\end{frame}

\begin{frame}
  \frametitle{Layout and Vizualization}
  \framesubtitle{Example with Fruchterman and Reingold}

<<vizu_4, echo=TRUE>>=
par(mfrow=c(1,2))

plot(GLattice, layout=layout.fruchterman.reingold); title("5x5x5 lattice")

plot(GBlog   , layout=layout.fruchterman.reingold); title("blog network")
@
  
\end{frame}

% \begin{frame}[fragile, allowframebreaks]
%   \frametitle{Layout and Vizualization: \textbf{ggraph} way}
%  
% <<ggraph_vizu_1, echo=TRUE>>=
% library(ggraph)
% library(gridExtra)
% g1 <- ggraph(GBlog, layout = "fr") + 
%   geom_edge_link(color = "lightgray") + geom_node_point() + theme_void()
% 
% g2 <- ggraph(GBlog   , layout = "kk") + 
%   geom_edge_link(color = "lightgray") + geom_node_point() + theme_void()
% 
% g3 <- ggraph(GBlog, layout = "linear") + 
%   geom_edge_arc(aes(alpha=..index..), show.legend = FALSE) + 
%   geom_node_point() + theme_void()
% 
% g4 <- ggraph(GBlog   , layout = "linear", circular = TRUE) + 
%   geom_edge_link(aes(alpha=..index..), show.legend = FALSE) + 
%   geom_node_point() + theme_void()
% 
% grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)
% @
% \end{frame}

\begin{frame}
  \frametitle{Layout and Vizualization}
  \framesubtitle{Do not be fooled by the plot}

<<vizu_5, echo=TRUE>>=
g.tree <- graph.formula(1-+2,1-+3,1-+4,2-+5,2-+6,2-+7, 3-+8,3-+9,4-+10)

par(mfrow=c(1, 3))

igraph.options(vertex.size=30, edge.arrow.size=0.5, vertex.label=NULL)

plot(g.tree, layout=layout.circle)

plot(g.tree, layout=layout.reingold.tilford(g.tree,  circular=T))

plot(g.tree, layout=layout.reingold.tilford)
@
  
\end{frame}


%% ==========================================================================
\section{Descriptive statistics}
%% ==========================================================================

%% ==========================================================================
\subsection{Vertex characteristics}

\begin{frame}
  \frametitle{Vertex degree}
  
  \begin{definition}[Degree distribution]
    In a graph $\clG = (\clV, \clE)$, recall that $d_i$ counts the number of incident edges in $\clE$ to $i$. Define $f_d$ to be
    the fraction of vertices $i\in \clV$ with degree $d_i=d$. The collection $\set{f_d, d\geq 0}$ is called the \alert{degree distribution} of $\clG$.
  \end{definition}
  
  \begin{block}{Property}
    Many real world networks have a degree distribution fitting well power law distributions: 
    \[
      f_{d_i}(d) = \P(d_i = d) = \frac{c}{d^\gamma}, \quad c\in\Rset, \gamma > 0.
    \]
  \end{block}
  Those heavy-tail distributions describe few vertices with very high degrees.
\end{frame}

\begin{frame}
  \frametitle{Vertex degree: example I}

<<degree_1>>=
library(sand) 
data(karate)

par(mfrow=c(1,2))
plot(karate)

hist(degree(karate), col=adjustcolor("lightblue", alpha.f = 0.5), main="")
@
      
\end{frame}

\begin{frame}
  \frametitle{Vertex degree: example II}

<<degree_2>>=
library(igraphdata) 
data(yeast)

degrees.yeast <- rev(sort(degree.distribution(yeast)))

plot(degrees.yeast[degrees.yeast!=0], log="xy", col=adjustcolor("blue", alpha.f = 0.5), pch=16, xlab="log degree", ylab="log-intensity")
@
      
\end{frame}

\begin{frame}[allowframebreaks]
  \frametitle{Distance and diameter}

  \begin{definition}[distance]
    \begin{itemize}
    \item \alert{The Length}  of a path $e_1,\dots, e_k$ is the number of edges enterin the path (here $k$).
    \item If two nodes $i,j$ are connected in $G$, then \alert{the distance} $\ell_{ij}$ is the length of the shortest path between $i$ and $j$. If the two nodes are not connected then $\ell_{ij} = \infty$.
    \end{itemize}
  \end{definition}

  \begin{definition}[diameter]
    The diameter of $\clG$ is the greatest distance between two nodes:
    \[
      \mathrm{diameter(\clG)} = \max_{(i,j)\in\clV\times\clV} \left(\ell_{ij}\right)
    \]
  \end{definition}

\end{frame}

\begin{frame}[fragile,allowframebreaks]
  \frametitle{Distance, Diameter: example}
<<distances1>>=
library(Matrix)
data(ppi.CC)
diameter(ppi.CC)
average.path.length(ppi.CC)
image(Matrix(distances(ppi.CC)))
@
\end{frame}

\begin{frame}
  \frametitle{Vertex centrality: closeness}

  \begin{block}{Question}
    How important is the node/vertice in the network?
  \end{block}

  \begin{definition}[Farness, Closeness]
    Farness is the sum of the length of the shortest paths between the node and all other nodes in the graph. Closeness is defined as its reciprocal:
    \[C(x)={\frac  {1}{\sum _{y}d(y,x)}}.\]
    $\rightsquigarrow$ \textit{The more central a node is, the closer it is to all other nodes.}
  \end{definition}

\end{frame}

\begin{frame}
  \frametitle{Vertex centrality: betweenness}

  \begin{block}{Question}
    How important is the node/vertice in the network?
  \end{block}

  \begin{definition}[Betweenness]
    For every pairs of vertices, there exists at least one shortest path between the vertices such that the number of edges that the path passes through is minimized.
    The betweenness centrality for each vertex is the number of these shortest paths that pass through the vertex: 
    \[
        g(i)=\sum _{{j\neq i\neq k}}{\frac  {\sigma _{{jk}}(i)}{\sigma _{{jk}}}}    
    \]
    where $\sigma _{jk}$ is the total number of shortest paths from node $j$ to node $k$ and $\sigma _{jk}(i)$ the number of those paths that pass through $i$.

  \end{definition}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Example for karate club data set}
  \framesubtitle{administrator and instructor are in blue and yellow}

<<density, cache=TRUE, echo=FALSE, out.width='\\textwidth'>>=
library(sna)

A <- get.adjacency(karate, sparse=FALSE)
library(network)
g <- network::as.network.matrix(A)
par(mfrow=c(1,3))
sna::gplot.target(g, degree(g), main="Degree",circ.lab = FALSE, circ.col="skyblue", usearrows = FALSE, vertex.col=c("blue", rep("red", 32), "yellow"), edge.col="darkgray")
sna::gplot.target(g, closeness(g), main="Closeness",
   circ.lab = FALSE, circ.col="skyblue",
   usearrows = FALSE,
   vertex.col=c("blue", rep("red", 32), "yellow"),
   edge.col="darkgray")
sna::gplot.target(g, betweenness(g), main="Betweeness",
   circ.lab = FALSE, circ.col="skyblue",
   usearrows = FALSE,
   vertex.col=c("blue", rep("red", 32), "yellow"),
   edge.col="darkgray")
@

<<echo=FALSE, results=FALSE>>=
rm(sna)
@

\end{frame}

% \begin{frame}
%   \frametitle{Jaccard Coefficient}
% 
%   \begin{definition}[Jaccard Coefficient or Jaccard Index]
% The Jaccard coefficient \alert{measures similarity between finite sample sets}, and is defined as the size of the intersection divided by the size of the union of the sample sets:
%   \[
%   J(A,B)=\frac{|A\cap B|}{|A\cup B|} =\frac{|A\cap B|}{|A|+|B|-|A\cap B|}.
%   \]
%   \end{definition}
% 
%   \begin{block}{Example}
%   It can be used to compared two sets of egdes. For instance
%   \begin{itemize}
%     \item for two networks $\clG$ and $\clH$ defined on the same set of node, we can compare the sets $\clE_\clG$ and $\clE_\clH$.
%     \item for a networks $\clG$ we can compute similarity between nodes with the Jaccard index and use it to define a weighted graph of similarity.
%   \end{itemize}
%   \end{block}
% 
% \end{frame}
% 
% \begin{frame}[fragile]
%   \frametitle{Jaccard Coefficient: example}
% 
% Plot the yeast PPI interaction network
% <<jaccard>>=
% library(sand)
% library(igraph)
% plot(ppi.CC, vertex.size=6, vertex.label=NA, layout=layout_in_circle)
% @
% 
% \end{frame}
% 
% \begin{frame}[fragile]
%   \frametitle{Jaccard Coefficient: example II}
% 
% Compute Jaccard similarity between vertices and give a image of this
% <<jaccardplot>>=
% library(Matrix)
% image(Matrix(igraph::similarity(ppi.CC, method = "jaccard")))
% @
% 
% \end{frame}

%% ==========================================================================
\subsection{Local measurements}

\begin{frame}
  \frametitle{Density}

  \begin{block}{Question}
    Is the network locally \alert{dense} in some sense?
  \end{block}

  \begin{definition}[Clique]
    In an undirected graph, a clique is a subset of the vertices such that \alert{every two distinct vertices are adjacent}.
  \end{definition}


  \begin{definition}[Density]
    The density of a (sub)-graph $\clG = (\clV,\clE)$ is defined by
    \[
      \mathrm{density}(\clG) = \frac{2|\clE|}{|\clV|(|\clV| - 1)} = \frac{\bar{D}}{|V|-1},
    \]
    where $\bar{D}$ is the mean degree of the network: how much $\clG$ is close to a clique? 
  \end{definition}

\end{frame}

\begin{frame}
  \frametitle{Clustering}

  \begin{block}{Question}
    Is the network locally \alert{dense} in some sense?
  \end{block}

  \begin{definition}[Triangle]
    Triplets of vertices in the graph that are connected through a triangle. They correspond to transitive relationships. We let 
    \begin{itemize}
      \item $\tau_{\Delta}(i)$ be the number of triangles in $\clG$ where $i$ falls.
      \item $\tau_{3}(i)$ be the number of triplets in $\clG$ where $i$ falls.
    \end{itemize}    
  \end{definition}


  \begin{definition}[Clustering coefficient]
    \[
      \mathrm{clustering}(\clG) = \frac{1}{\clV_2} \sum_{i\in\clV_2} \tau_{\Delta}(i) / \tau_3(i),
    \]
    where $\clV_2$ is the set of vertices whose degree is greater or equal to 2.
  \end{definition}

\end{frame}

\begin{frame}
  \frametitle{Transitivity}

  \begin{block}{Question}
    Is the network locally \alert{dense} in some sense?
  \end{block}

  \begin{definition}[Triangle]
    Triplet of vertices in the graph that are connected through a triangle. They correspond to transitive relationships. We let 
    \begin{itemize}
      \item $\tau_{\Delta}(i)$ be the number of triangle in $\clG$ where $i$ falls.
      \item $\tau_{3}(i)$ be the number of triplet in $\clG$ where $i$ falls.
    \end{itemize}    
  \end{definition}

  \begin{definition}[Transitivity]
    
    \[
      \mathrm{transitivity}(\clG) = \frac{\sum_{\clV}\tau_{\Delta}(i)}{\sum_{\clV}\tau_3(i)},
    \]
  \end{definition}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Local density: example}

<<echo=FALSE, cache = FALSE>>=
rm(sna)
library(igraph)
library(sand)
@

Create ego graphs around teacher and instructor
<<density2, cache = FALSE>>=
data(karate)
ego.instr <- igraph::induced_subgraph(karate, igraph::neighborhood(karate, 1, 1)[[1]])
ego.admin <- igraph::induced_subgraph(karate, igraph::neighborhood(karate, 1, 34)[[1]])
@

<<density3, echo=FALSE, cache = FALSE>>=
par(mfrow=c(1,3))
plot(karate)
plot(ego.instr)
plot(ego.admin)
@

\end{frame}

\begin{frame}[fragile]
  \frametitle{Local density: example (II)}

Look for graph density and transitivity/clustering either globally or locally
<<density5, cache = FALSE>>=
graph.density(karate)
graph.density(ego.instr)
graph.density(ego.admin)
transitivity(karate)
transitivity(karate, "local", vids = c(1,34))
@

\end{frame}


%% ==========================================================================
\section{Graph Partionning}
%% ==========================================================================

\begin{frame}
  \frametitle{Principle of graph partionning}

  \begin{definition}[Partition]
    A decomposition $\mathcal{C} = \{C_1,\dots,C_K\}$ of the vertices $\clV$ such that
    \begin{itemize}
      \item $C_k \cap C_{k'} = \emptyset$ for any $k\neq k'$
      \item $\bigcup_{k} C_k = \clV$
    \end{itemize}
  \end{definition}

  \vfill

  \begin{block}{Goal of graph paritionning}
    Form a partition of the vertices with unsupervized approach where the $\mathcal{C}$ is composed by \alert{"cohesive"} sets of vertices, for instance,
    \begin{enumerate}
      \item vertices well connected among themselves
      \item well separated from the remaining vertices
    \end{enumerate}
    
  \end{block}

\end{frame}

%% ==========================================================================
\subsection{Hierarchical clustering}

\begin{frame}
  \frametitle{Principle}
  \framesubtitle{}

  \begin{algorithm}[H]
    \KwIn{$n$ individuals with $p$ attributes)}
    \BlankLine\BlankLine
    \DontPrintSemicolon
      1. Compute the dissimilarity between groups \;
      2. Regroup the two most similar elements \;
      
      Iterate until all element are in a single group \;
    \BlankLine\BlankLine
    \KwOut{$n$ nested partitions from $\set{\set{1},\dots,\set{n}}$ to $\set{\set{1,\dots,n}}$}

    \caption{Agglomerative hierarchical clustering}
  \end{algorithm}
  
  \begin{block}{Ingredients}
    \begin{enumerate}
      \item a dissimilarity measure between singleton
      \item a distance measure between sets
    \end{enumerate}
  \end{block}

  \begin{block}{Graph-specific}
    For instance, modularity, betweeness, clustering measure, etc.
  \end{block}

\end{frame}

\begin{frame}[fragile,allowframebreaks]
  \frametitle{Examples of graph clustering}

<<vizu_opt, echo=FALSE, cache = FALSE>>=
igraph.options(vertex.size=5, vertex.label=NA, edge.arrow.size=.5)
@

<<>>=
hc <- cluster_fast_greedy(karate)
plot(hc,karate)
@

<<>>=
hc <- cluster_edge_betweenness(karate)
plot(hc,karate)
@

<<>>=
hc <- cluster_louvain(karate)
plot(hc,karate)
@

<<>>=
hc <- cluster_walktrap(karate)
plot(hc,karate)
@

\end{frame}

%% ==========================================================================
\subsection{Spectral Clustering}

\begin{frame}
  \frametitle{Graph Laplacian}

  \begin{definition}[(Un-normalized) Laplacian]
    The Laplacian matrix $\bL$, resulting from the modified incidence matrix $\tilde\bB$ $\tilde{\! B}_{ij}= 1/-1$ if $i$ is incident to $j$ as tail/head, is defined by 
    \[
      \bL = \tilde \bB \tilde \bB^\intercal = \bD - \bA,
    \]
    where $\bD = \diag(d_i, i\in\clV)$ is the diagonal matrix of degrees. 
  \end{definition}

  \begin{block}{Remark}
    \begin{itemize}
    \item $\bL$ is called Laplacian by analogy to the second order derivative (see below).
    \item Spectrum of $\bL$ has much to say about the structure of the graph $\clG$.
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Spectral Clustering}
    
  \begin{block}{Principle}
  
  \begin{enumerate}
    \item Use the spectral property of $\bL$ to perform clustering in the eigen space \medskip
    \item If the network have $K$ connected components, the first $K$ eigenvectors are $\mathbf{1}$ span the eigenspace associated with eigenvalue $0$ \medskip
    \item Applying a simple clustering algorithm to the rows of the $K$ first eigenvectors separate the components
  \end{enumerate}
  $\rightsquigarrow$ This principle generalizes to a graph with a single component: spectral clustering tends to separates groups of nodes which are highly connected together
  
  \end{block}
  
\end{frame}

\begin{frame}[fragile]
  \frametitle{Clustering based on the first non null eigenvalue}
  
<<>>=
hc <- cluster_leading_eigen(karate)
plot(hc,karate)
@

\end{frame}

%% ==========================================================================
%% ==========================================================================
\section{The Stochastic Block Model (SBM)}
%% ==========================================================================

\begin{frame}
  \frametitle{Motivations}

  \begin{block}{Previous Section: \alert{find an underlying organization in a observed network}}
    Spectral or hierachical clustering for network data \\
    \begin{itemize}
      \item[$\rightsquigarrow$] \alert{Not model-based}, thus no statistical inference possible
    \end{itemize}
  \end{block}

  \begin{block}{This Section: \alert{clustering of network based on a probabilistic model of the graph}}<2->
    Become familiar with
    \begin{itemize}
      \item the stochastic block model, a random graph model tailored for clustering vertices
    \end{itemize}
  \end{block}

  \onslide<3>{
  \begin{center}
    hierarchical clustering $\leftrightarrow$ \alert{Gaussian mixture models} \\
      $\Updownarrow$ \\
    hierarchical/spectral clustering for network $\leftrightarrow$ Stochastic block model
  \end{center}
  }
\end{frame}

%% ==========================================================================
\subsection{Some Graphs Models and their limitations}
%% ==========================================================================

\begin{frame}
  \frametitle{A mathematical model: Erdös-Rényi graph}

  \begin{definition}
    Let $\clV = {1,\dots,n}$ be a set of fixed vertices. The (simple) Erdös-Rény model $\mathcal{G}(n,\pi)$ assumes random edges between pairs of nodes with probability $\pi$. In orther word, the (random) adjacency matrix $\bX$ is such that
    \begin{equation*}
      X_{ij} \sim \mathcal{B}(\pi)
    \end{equation*}
  \end{definition}

  \vfill

  \begin{proposition}[degree distribution]
    The (random) degree $D_i$ of vertex $i$ follows a binomial distribution:
      \begin{equation*}
        D_i \sim b(n-1, \pi).
      \end{equation*}
  \end{proposition}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Erdös-Rényi - example}

<<ER_example>>=
G1 <- igraph::sample_gnp(10, 0.1)
G2 <- igraph::sample_gnp(10, 0.9)
G3 <- igraph::sample_gnp(100, .02)
par(mfrow=c(1,3))
plot(G1, vertex.label=NA) ; plot(G2, vertex.label=NA)
plot(G3, vertex.label=NA, layout=layout.circle)
@
\end{frame}

\begin{frame}[fragile]
  \frametitle{Erdös-Rény - limitations: very homegeneous}

<<ER_limitation1>>=
average.path.length(G3); diameter(G3)
@

<<ER_limitation2, echo=FALSE>>=
par(mfrow=c(1,2))
hist(igraph::degree(G3), col="lightblue"); plot(cluster_fast_greedy(G3), G3)
@
\end{frame}

% \begin{frame}
%   \frametitle{Mechanism-based model: preferential attachment}
% 
%   The graph is defined dynamically as follows
%   \begin{block}{Definition}
%     Start from a initial graph $\mathcal{G}_0 = (\mathcal{V}_0,\mathcal{E}_0)$, then for each time step,
%     \begin{enumerate}
%       \item At $t$ a new node $V_t$ is added
%       \item $V_t$ is connected to $i \in V_{t-1}$ with probability
%       \begin{equation*}
%         D_i^\alpha + \mathrm{cst.}
%       \end{equation*}
%     \end{enumerate}
%   \end{block}
%   $\rightsquigarrow$ Nodes with high degree get more connections thus \alert{richers get richers}
% \end{frame}
% 
% \begin{frame}[fragile]
%   \frametitle{Preferential attachment - example}
% 
% <<PA_example>>=
% G1 <- igraph::sample_pa(20, 1, directed=FALSE)
% G2 <- igraph::sample_pa(20, 5, directed=FALSE)
% G3 <- igraph::sample_pa(200, directed=FALSE)
% par(mfrow=c(1,3))
% plot(G1, vertex.label=NA) ; plot(G2, vertex.label=NA)
% plot(G3, vertex.label=NA, layout=layout.circle)
% @
% 
% \end{frame}
% 
% \begin{frame}[fragile]
%   \frametitle{Preferential attachment - limitations}
% 
% <<PA_limitation1>>=
% average.path.length(G3); diameter(G3)
% @
% 
% <<PA_limitation2, echo=FALSE>>=
% par(mfrow=c(1,2))
% hist(degree(G3), col="lightblue"); plot(cluster_fast_greedy(G3), G3)
% @
% \end{frame}

\begin{frame}
  \frametitle{Limitations}

    \begin{itemize}
    \item \alert{Erdös-Rényi}\\
      The ER model does not fit well real world network
      \begin{itemize}
        \item As can been seen from its degree distribution
        \item ER is generally too homogeneous
      \end{itemize}
    \end{itemize}

  \vfill

  \begin{block}{The Stochastic Block Model}
    The SBM\footnote{Other models exist (e.g. exponential model for random graphs) but less popular.} generalizes ER in a mixture framework. It provides
    \begin{itemize}
      \item a statistical framework to adjust and interpret the parameters
      \item a flexible yet simple specification that fits many existing network data
    \end{itemize}
  \end{block}

\end{frame}


%% ==========================================================================
\subsection{Mixture of Erdös-Rényi and the SBM}
%% ==========================================================================

\begin{frame}
  \frametitle{Stochastic Block Model: definition}
    \framesubtitle{Mixture model point of view: mixture of Erdös-Rényi}

    \begin{block}{Latent structure}
      Let $\mathcal{V} = \set{1,..,n}$ be a fixed set of vertices. We give each $i\in\mathcal{V}$ a \alert{latent label} among a set $\mathcal{Q}=\{1,\dots,Q\}$ such that
    \begin{itemize}
    \item $\alpha_q = \prob(i\in q), \quad \sum_q \alpha_q=1$;
    \item $Z_{iq}=\1_{\{i \in  q\}}$  are independent  hidden variables.
   \end{itemize}
   \end{block}

    \begin{block}{The conditional distribution of the edges}
    Connexion probabilities depend on the node class belonging:
    \begin{equation*}
      X_{ij} | \set{i\in q, j\in\ell} \sim \mathcal{B}(\pi_{q \ell}) \qquad \bigg(\Leftrightarrow       X_{ij} | \set{Z_{iq}Z_{j\ell}=1} \sim \mathcal{B}(\pi_{q \ell}).
 \bigg)
    \end{equation*}
    The $Q\times Q$ matrix ${\boldsymbol\pi}$  gives for all couple of labels $\pi_{q\ell}=\mathbb{P}(X_{ij}=1|i\in q, j\in\ell)$.
   \end{block}

\end{frame}


\begin{frame}
  \frametitle{Stochastic Block Model: the big picture}

  \begin{center}
    \begin{overlayarea}{\textwidth}{.5\textheight}
      \begin{columns}
        \begin{column}{.45\paperwidth}
        \begin{tikzpicture}
          %% UN GRAPH

          \tikzstyle{every edge}=[-,>=stealth',shorten >=1pt,auto,thin,draw]
          \tikzstyle{every state}=[draw=none,text=white,scale=0.65, font=\scriptsize, transform shape]
          \tikzstyle{every node}=[fill=yellow!40!orange]
          % premier cluster
          \node[state] (A1) at (0,0.5) {A1};
          \node[state] (A2) at (1,0.5) {A2};
          \node[state] (A3) at (.5,1.5) {A3};

          \path (A2) edge [bend left] node[fill=white,below=.1cm]
          {$\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{yellow!40!orange}{\bullet}}$}
          (A1)
          (A1) edge [bend left] (A3)
          (A3) edge [bend left] (A2);

          \tikzstyle{every node}=[fill=blue!80!black]
          \foreach \angle/\text in {234/B1, 162/B2, 90/B3, 18/B4, -54/B5} {
            \node[fill=blue,state,xshift=5cm,yshift=3.5cm]     (\text)    at
            (\angle:1cm) {\text};
          }
          \path (B2) edge (B5)
          (B1) edge (B4);
          \foreach \from/\to in {1/2,2/3,4/5,5/1}{
            \path (B\from) edge [bend left] (B\to);
          }

          \path    (B3)    edge     [bend    left]    node[fill=white]
          {$\pi_{\textcolor{blue!80!black}{\bullet}\textcolor{blue!80!black}{\bullet}}$}  (B4) ;

          \tikzstyle{every node}=[fill=green!50!black]
          % troisieme cluster
          \node[state] (C1) at (3,-.5) {C1};
          \node[state] (C2) at (4,0) {C2};

          \path (C1) edge [bend right] node[fill=white,below=.25cm]
          {$\pi_{\textcolor{green!50!black}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (C2);

          % inter cluster
          \path (A3) edge [bend right]  (B2)
          (A3)    edge    [bend    left]    node[fill=white]
          {$\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}$}
          (B3)
          (C2) edge [bend right] node[fill=white,right]
          {$\pi_{\textcolor{blue!80!black}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (B4)
          (A2) edge [bend right] node[fill=white]
          {$\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{green!50!black}{\bullet}}$}
          (C1);
        \end{tikzpicture}
        \end{column}
        \begin{column}{.5\paperwidth}
          \begin{small}
            \begin{block}{Stochastic Block Model}
              Let $n$ nodes divided into
              \begin{itemize}
              \item
                $\mathcal{Q}=\{\textcolor{yellow!40!orange}{\bullet},\textcolor{blue!80!black}{\bullet},\textcolor{green!50!black}{\bullet}\}$
                classes
              \item  $\alpha_\bullet  =  \mathbb{P}(i  \in  \bullet)$,
                $\bullet\in\mathcal{Q},i=1,\dots,n$
              \item      $\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}     =      \mathbb{P}(i
                \leftrightarrow j | i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet})$
              \end{itemize}
            \end{block}
          \end{small}
        \end{column}
      \end{columns}
    \end{overlayarea}
  \end{center}

  \begin{align*}
    Z_i = \mathbf{1}_{\{i \in \bullet\}}  \ & \sim^{\text{iid}} \mathcal{M}(1,\alpha), \quad \forall\bullet\in\mathcal{Q}, \\
    X_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\} & \sim^{\text{ind}} \mathcal{B}(\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}})\\
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{Stochastic Block Model: unknown parameters}

    \begin{center}
  \begin{overlayarea}{\textwidth}{.5\textheight}
      \begin{columns}
        \begin{column}{.45\paperwidth}
        \begin{tikzpicture}
          %% UN GRAPH

          \tikzstyle{every edge}=[-,>=stealth',shorten >=1pt,auto,thin,draw]
          \tikzstyle{every state}=[draw=none,text=white,scale=0.65, font=\scriptsize, transform shape]
          \tikzstyle{every node}=[fill=gray]
          % premier cluster
          \node[state] (A1) at (0,0.5) {N1};
          \node[state] (A2) at (1,0.5) {N2};
          \node[state] (A3) at (.5,1.5) {N3};

          \path (A2) edge [bend left] node[fill=white,below=.1cm]
          {}
          (A1)
          (A1) edge [bend left] (A3)
          (A3) edge [bend left] (A2);

          \tikzstyle{every node}=[fill=blue!80!black]
          \foreach \angle/\text in {234/N1, 162/N2, 90/N3, 18/N4, -54/N5} {
            \node[fill=gray,state,xshift=5cm,yshift=3.5cm]     (\text)    at
            (\angle:1cm) {\text};
          }
          \path (B2) edge (B5)
          (B1) edge (B4);
          \foreach \from/\to in {1/2,2/3,4/5,5/1}{
            \path (B\from) edge [bend left] (B\to);
          }

          \path (B3) edge [bend left] node[fill=white] {}  (B4) ;

          \tikzstyle{every node}=[fill=gray]
          % troisime cluster
          \node[state] (C1) at (3,-.5) {N1};
          \node[state] (C2) at (4,0) {N2};

          \path (C1) edge [bend right] (C2);

          % inter cluster
          \path (A3) edge [bend right]  (B2)
          (A3)    edge    [bend    left]    node[fill=white]
          {}
          (B3)
          (C2) edge [bend right] node[fill=white,right]
          {}
          (B4)
          (A2) edge [bend right] node[fill=white]
          {}
          (C1);
        \end{tikzpicture}
        \end{column}
        \begin{column}{.5\paperwidth}
          \begin{small}
            \begin{block}{Stochastic Block Model}
              Let $n$ nodes divided into
              \begin{itemize}
              \item
                $\mathcal{Q}=\{\textcolor{yellow!40!orange}{\bullet},\textcolor{blue!80!black}{\bullet},\textcolor{green!50!black}{\bullet}\}$,
                $\text{card}(\mathcal{Q})$ known
              \item  $\alpha_\bullet  =  ?$,
              \item      $\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}}     =      ?$
              \end{itemize}
            \end{block}
          \end{small}
        \end{column}
      \end{columns}
    \end{overlayarea}
    \end{center}

  \begin{align*}
    Z_i = \mathbf{1}_{\{i \in \bullet\}}  \ & \sim^{\text{iid}} \mathcal{M}(1,\alpha), \quad \forall\bullet\in\mathcal{Q}, \\
    X_{ij} \ | \ \{i\in\textcolor{yellow!40!orange}{\bullet},j\in\textcolor{blue!80!black}{\bullet}\} & \sim^{\text{ind}} \mathcal{B}(\pi_{\textcolor{yellow!40!orange}{\bullet}\textcolor{blue!80!black}{\bullet}})\\
  \end{align*}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Stochastic block models -- examples of topology}
  \framesubtitle{Community network}

<<>>=
pi <- matrix(c(0.3,0.02,0.02,0.02,0.3,0.02,0.02,0.02,0.3),3,3)
communities <- igraph::sample_sbm(100, pi, c(25, 50, 25))
plot(communities, vertex.label=NA, vertex.color = rep(1:3,c(25, 50, 25)))
@

\end{frame}

\begin{frame}[fragile]
  \frametitle{Stochastic block models -- examples of topology}
  \framesubtitle{Star network}

<<>>=
pi <- matrix(c(0.05,0.3,0.3,0),2,2)
star <- igraph::sample_sbm(100, pi, c(4, 96))
plot(star, vertex.label=NA, vertex.color = rep(1:2,c(4,96)))
@

\end{frame}

% \begin{frame}
%   \frametitle{Degree distributions}
% 
%   \begin{block}{Conditional degree distribution}
%     The conditional degree distribution of a node $i\in q$ is
%     \begin{equation*}
%       D_i | i \in q \sim \mathrm{b}(n-1,\bar\pi) \approx \mathcal{P}(\lambda_q), \qquad \bar\pi_q = \sum_{\ell=1}^Q \alpha_\ell, \pi_{q\ell} \quad \lambda_q = (n-1)\bar\pi_q
%     \end{equation*}
%   \end{block}
% 
%   \vfill
% 
%   \begin{block}{Conditional degree distribution}
%     The degree distribution of a node $i$ can be approximated by a mixture of Poisson distributions:
%     \begin{equation*}
%       \prob(D_i = k) = \sum_{q=1}^Q\alpha_q \exp{\set{-\lambda_q}} \ \frac{\lambda_q^k}{k !}
%     \end{equation*}
%   \end{block}
% 
% \end{frame}
% 

\begin{frame}
  \frametitle{Likelihoods for Expectation Maximization}

  \begin{block}{Complete-data loglikelihood}
    \vspace{-.5cm}
    \begin{equation*}
      \log L(\bX,\bZ) = \sum_{i,q} Z_{iq} \log \alpha_q + \sum_{i<j,q,\ell} Z_{iq}Z_{j\ell} \log \pi_{q\ell}^{X_{ij}} (1-\pi_{q\ell})^{1-X_{ij}}.
    \end{equation*}
  \end{block}

  \begin{block}{Conditional expectation of the complete-data loglikelihood}
    \vspace{-.5cm}
    \begin{equation*}
      \E_{\bZ|\bX} \big[\log L(\btheta;\bX,\bZ) \big] = \sum_{i,q} \tau_{iq} \log \alpha_q + \sum_{i<j,q,\ell} \eta_{ijq\ell} \log \pi_{q\ell}^{X_{ij}} (1-\pi_{q\ell})^{1-X_{ij}}
    \end{equation*}
      where $\tau_ {iq}, \eta_{ijq\ell}$ are the posterior probabilities:
      \begin{itemize}
        \item $\tau_{iq} = \prob(Z_{iq} = 1 | \bX) = \E \left[Z_{iq} | \bX\right].$
        \item $\eta_{ijq\ell} = \prob(Z_{iq}Z_{j\ell} = 1 | \bX) = \E \left[Z_{iq}Z_{j\ell} | \bX\right].$
      \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Inference in the SBM}
  \framesubtitle{The EM strategy does not apply}
  
  \begin{block}{Ouch: another intractability problem}
    \begin{itemize}
      \item the $Z_{iq}$ are \alert{not independent} in the SBM framework\dots
      \item we cannot compute $\eta_{ijq\ell} = \prob(Z_{iq}Z_{j\ell} = 1 | \bX) = \E \left[Z_{iq}Z_{j\ell} | \bX\right]$,
      \item the conditional expectation $Q(\btheta)$, i.e. the main EM ingredient, is \alert{intractable}.
    \end{itemize}
  \end{block}

  \vfill

  \begin{block}{Solution: mean field approximation (variational inference)}
    Approximate $\eta_{ijq\ell}$ by $\tau_{iq}\tau_{j\ell}$, i.e., \alert{assume independence between $Z_{iq}$}\\

    $\rightsquigarrow$ This can be formalized in the variational framework
  \end{block}


\end{frame}

\begin{frame}
  \frametitle{Model selection: the number of blocks/clusters}

  We use our lower bound of the  loglikelihood to compute an approximation of the ICL
  \begin{multline*}
  \mathrm{vICL}(Q) = \E_{\hat{\mathbb{Q}}} [\log L(\hat{\btheta)};\bX,\bZ] \\ - \frac{1}{2} \left(\frac{Q(Q+1)}{2} \log \frac{n(n-1)}{2} + (Q-1) \log (n) \right),
\end{multline*}
where
    \begin{equation*}
      \E_{\hat{\mathbb{Q}}} [\log L(\hat\btheta; \bX,\bZ)] = J(\hat{\boldsymbol\tau},\hat\btheta) - \mathcal{H}(\hat{\mathbb{Q}}).
    \end{equation*}

    The variational BIC is just
    \begin{equation*}
  \mathrm{vBIC}(Q) = J(\hat{\boldsymbol\tau},\hat\btheta) - \frac{1}{2} \left(\frac{Q(Q+1)}{2} \log \frac{n(n-1)}{2} + (Q-1) \log (n) \right).
    \end{equation*}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Example on the French blogsphere (I)}

<<example blockmodels 2, cache = TRUE>>=
library(blockmodels)
library(sand)

adj_blog <- upgrade_graph(fblog) %>% 
    as_adjacency_matrix() %>% 
    as.matrix()

mySBM_collection <- BM_bernoulli(
  "SBM_sym", 
  adj_blog, verbosity = 0, 
  plotting = "figures/ICL_fblog.pdf"
)
mySBM_collection$estimate()
@

\end{frame}

\begin{frame}[fragile]
  \frametitle{Example on the French blogsphere (II)}

\includegraphics[width=.7\textwidth]{figures/ICL_fblog}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Example on the French blogsphere (III)}

<<example blockmodels 3>>=
clusters <- 
  apply(mySBM_collection$memberships[[10]]$Z, 1, which.max)
image(Matrix(adj_blog[order(clusters), order(clusters)]))
@

\end{frame}


\begin{frame}[fragile,allowframebreaks]
  \frametitle{Example on the French blogsphere (IV)}

<<example blockmodels 4, fig.align="center", fig.height=8>>=
library(RColorBrewer); pal <- brewer.pal(10, "Set3")

g <- graph_from_adjacency_matrix(adj_blog, mode = "undirected", weighted = TRUE, diag = FALSE)
V(g)$class <- clusters
V(g)$size <- 5
V(g)$frame.color <- "white"
V(g)$color <- pal[V(g)$class]
V(g)$label <- ""
E(g)$arrow.mode <- 0

par(mar =c(0,0,0,0))
plot(g, edge.width=E(g)$weight)
@

\end{frame}

\end{document}

